
**Celery** – это _асинхронная распределенная очередь задач_, написанная на Python, она предназначена для обработки сообщений в реальном времени при помощи многозадачности. Используя Celery, **можно организовать выполнение задач в фоновом режиме**, не загружая основной поток приложения.

# КАК ОН РАБОТАЕТ В ДЕТАЛЯХ

**Celery** — **это** программа, которая отслеживает **задачи** (`tasks`), которые необходимо выполнить, и в которой есть набор **обработчиков** (`workers`), которые будут выполнять эти задачи. Основной смысл в том, что она (программа) может выполнять несколько задач **параллельно** и что она **не блокирует** поставщиков (`producers`) этих самых задач.

Celery на самом деле не хранит все эти задачи в памяти. Для хранения задач есть отдельный сервис, называемый брокером сообщений (`message broker`), который по сути своей является очередью. Обычно это либо [Redis](https://redis.io/), либо [RabbitMQ](https://www.rabbitmq.com/). Т.е. Celery следит за тем, что происходит в очереди, но хранится она внутри Redis/RabbitMQ.

При запуске Celery создается 1 обработчик.

```
celery -A tasks worker
```

Этот обработчик является главным процессом (`supervisor process`), который будет порождать дочерние процессы или потоки, которые в свою очередь будут выполнять задачи. По умолчанию главный обработчик будет создавать **дочерние процессы, а не потоки**, и он создаст столько одновременных дочерних процессов, сколько ядер у процессора. Главный процесс будет следить за тем, что происходит с задачами и процессами/потоками, но он не будет запускать сами задачи. Эта группа дочерних процессов или потоков, которая ожидает выполнения задач, называется **пулом выполнения** (`execution pool`) или **пулом потоков** (`thread pool`).

дальше подробнее читаем в [статье](https://habr.com/ru/articles/686820/), потому что иначе просто будет Ctrl+C Ctrl+V с Хабр

# КАК ИСПОЛЬЗОВАТЬ

_Используя Celery можно легко организовать выполнение фоновых задач._

Объявляется объект класса Celery с некоторыми параметрами в коде для решения фоновых задач в нашем API 

```
celery = Celery('название', broker='ссылка на брокер: redis://redis:6379 как пример')
```

 Теперь мы можем определить фоновые задачи с помощью декоратора `@celery.task`. К примеру функция, которая просто складывает два числа:

```
@celery.task
def add(x, y):
	return x + y
```

`add` — это асинхронная задача. Можно вызвать её с помощью `add.delay(x, y)`.

Celery предлагает параметры для настройки задач:

`ignore_result` Если не нужен результат выполнения задачи, есть параметр :

```
@app.task(ignore_result=True)def add(x, y):    return x + y
```

`rate_limit` ограничивает скорость выполнения задач. Например, если нужно, чтобы задача `add` выполнялась чаще, чем 10 раз в минуту, можно настроить `rate_limit`:

```
@app.task(rate_limit='10/m')def add(x, y):    return x + y
```

**retry**

Задача может иногда терпеть неудачу из-за проблем (которые бывают):

```
@app.task(bind=True, max_retries=3, default_retry_delay=60)def add(self, x, y):    try:        # Попытка выполнения задачи        return x + y    except SomeTemporaryException as exc:        # Запланировать повторное выполнение задачи        raise self.retry(exc=exc)
```

Задача попытается выполниться до 3 раз с интервалом в 60 секунд, если возникнет временная ошибка.

# ВЫЗОВ ЗАДАЧ Celery

Затем мы можем вызвать уже эту фоновую задачу в наших ендпоинтах: 

Метод `delay()` — это самый простой способ вызвать задачу асинхронно. Под капотом он использует `apply_async()`:

```
from tasks import add# Вызов задачи асинхронноresult = add.delay(4, 4)
```

`apply_async()` предлагает больше гибкости, позволяя указать различные параметры выполнения: время и приоритет выполнения, а также колбэки и errbacks:

```
result = add.apply_async((4, 4), countdown=10)
```

`add` будет запланирована к выполнению через 10 секунд после вызова.

`signature()` создает подпись задачи, которую можно использовать для создания сложных раб. процессов:

```
from celery import signaturesig = signature('tasks.add', args=(2, 2), immutable=True)sig.delay()
```

`chain()` позволяет соединить несколько задач в одну последовательность, где результат одной задачи передается в качестве аргумента следующей:

```
from celery import chain# (4 + 4) -> (8 * 10)res = chain(add.s(4, 4), multiply.s(10))()
```

`group()` используется для параллельного выполнения набора задач. Он возвращает специальный объект `GroupResult`, который позволяет отслеживать выполнение группы задач:

```
from celery import group# выполняет add(2, 2) и add(4, 4) параллельноgroup_result = group(add.s(2, 2), add.s(4, 4))()
```

`chord()` — это комбинация `group()` и `chain()`, позволяющая выполнить группу задач параллельно и затем вызвать callback-задачу с результатами группы:

```
from celery import chord# cначала выполняет add(2, 2) и add(4, 4) параллельно, затем результаты передаются в multiply()result = chord([add.s(2, 2), add.s(4, 4)])(multiply.s(2))
```